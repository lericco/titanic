{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6155138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learnig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6458d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab32fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# União das duas tabelas para o tratamento da base\n",
    "frame = pd.concat([train_df, test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a779959",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8a832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A variável \"Cabin\" será excluída, pois possui muitos valores ausentes e não há possibilidade de gerar artificialmente\n",
    "# novos valores.\n",
    "# A variável \"Ticket\" também será excluída, pois são valores alfanuméricos sem padrão definido e não são passíveis de \n",
    "# ranqueamento\n",
    "# A variável nome não interfere no resultado, também será excluída\n",
    "\n",
    "frame.drop(['Cabin', 'Ticket', 'Name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b41d23",
   "metadata": {},
   "source": [
    "## Classficação das variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04efd79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = frame['Survived'].value_counts()\n",
    "labels = ['Morreu', 'Viveu']\n",
    "explode = [0.1, 0]\n",
    "\n",
    "plt.pie(size, explode=explode, labels=labels, autopct='%1.1f', shadow=True, startangle=270)\n",
    "plt.title('Percentual de sobreviventes')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b41ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked']\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "for i in range(0, len(colunas)):\n",
    "    df_plot = frame.groupby([colunas[i], 'Survived']).count()['PassengerId'].rename('count')\n",
    "    df_plot = (df_plot / df_plot.groupby(level=0).sum()).reset_index()\n",
    "    df_plot = df_plot[df_plot['Survived'] == 0]\n",
    "\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.bar(df_plot[colunas[i]], df_plot['count'])\n",
    "    plt.title(colunas[i])\n",
    "    plt.ylabel('Não sobreviveu')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dece50",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = frame.drop(['Survived', 'PassengerId'], axis=1)\n",
    "corr_matrix = corr_matrix.corr().abs()\n",
    "plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c659d3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8895cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161896fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[['Embarked', 'Survived']].groupby(['Embarked'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5b7219",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86317187",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4446c4",
   "metadata": {},
   "source": [
    "# Transformação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb9fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar Sex e Embarked em valor numérico\n",
    "# Porto embarque: C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "sex = {'male': 0, 'female': 1}\n",
    "frame['Sex'] = frame['Sex'].map(sex)\n",
    "\n",
    "port = {'C': 1, 'Q': 2, 'S': 3}\n",
    "frame['Embarked'] = frame['Embarked'].map(port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758db71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_ages = np.zeros((2, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbb716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar\n",
    "# 1 - as idades das pessoas que não possem a informação com a média para a classe e sexo\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        ages = frame.loc[(frame['Sex'] == i) & (frame['Pclass'] == j+1)]['Age'].mean()\n",
    "        mean_ages[i, j] = ages\n",
    "\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        frame.loc[(frame['Age'].isnull()) & (frame['Sex'] == i) & (frame['Pclass'] == j+1), 'Age'] = mean_ages[i, j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd21c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - o local de embarque para duas pessoas que não apresentam essa informação\n",
    "# Será utilizada a moda dos valores de embarque.\n",
    "\n",
    "frame['Embarked'].fillna(frame['Embarked'].dropna().mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573056d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - o Fare para uma pessoa não apresenta valor\n",
    "# Será utilizada a média dos valores considerando local de embarque e a classe.\n",
    "\n",
    "frame['Fare'].fillna(frame[(frame['Fare'].notnull()) & (frame['Pclass'] == 3) & (frame['Embarked'] == 3)]['Fare'].mean(),\n",
    "                         inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94acc74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização/padronização das informações de Age e de Fare\n",
    "# StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2352778",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Age', 'Fare']\n",
    "\n",
    "for i in features:\n",
    "    var = np.array(frame[i]).reshape(-1, 1)\n",
    "    scaler.fit(var)\n",
    "    frame[i] = scaler.transform(var)\n",
    "    plt.hist(frame[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ec566",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_treino = frame[frame['Survived'].notnull()]\n",
    "df_teste = frame[frame['Survived'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0273bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split do DataFrame de treino em duas partes, para validar os modelos\n",
    "\n",
    "Y = df_treino['Survived']\n",
    "X = df_treino.drop(['PassengerId', 'Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e55e21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30)\n",
    "\n",
    "print('X_train: ', X_train.shape)\n",
    "print('X_test: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42363b8",
   "metadata": {},
   "source": [
    "# Randon Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c3931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro avaliar os resultados do treino, utilizando as métricas para identificar overfitting\n",
    "# Depois fazer a previsão.\n",
    "# Técnicas:\n",
    "# 1-Cross Validation\n",
    "# 2-ROC\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, Y_train)\n",
    "\n",
    "# Fazendo previsão\n",
    "Y_pred = rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea767944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation do treino\n",
    "# Se acurácia das bases de treino e de teste forem próximas, pode indicar que não há overfitting\n",
    "# Usar a base de treino para fazer a 1ª validação\n",
    "\n",
    "scores_rf = cross_val_score(rf, X_train, Y_train, cv=10, scoring='accuracy', n_jobs= -1)\n",
    "print('Cross validation treino: Média = {:.3f} Desvio Padrão = {:.3f}' .format(np.mean(scores_rf), np.std(scores_rf)))\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "#Confusion Matrix\n",
    "print('Confusion Matrix em Teste')\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "# Acurácia das previsões em relação ao resultado real\n",
    "print('Acurácia em Teste: ', accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e369dd",
   "metadata": {},
   "source": [
    "# Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d30b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0)\n",
    "gbc.fit(X_train, Y_train)\n",
    "\n",
    "# Previsão\n",
    "Y_pred = gbc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3dcd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_gbc = cross_val_score(gbc, X_train, Y_train, cv=10, scoring='accuracy', n_jobs= -1)\n",
    "print('Cross validation treino: Média = {:.3f} Desvio Padrão = {:.3f}' .format(np.mean(scores_gbc), np.std(scores_gbc)))\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "#Confusion Matrix\n",
    "print('Confusion Matrix em Teste')\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "# Acurácia das previsões em relação ao resultado real\n",
    "print('Acurácia em Teste: ', accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597d22b1",
   "metadata": {},
   "source": [
    "# Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897a47a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, Y_train)\n",
    "\n",
    "# Fazendo previsão\n",
    "Y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1521cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_lr = cross_val_score(lr, X_train, Y_train, cv=10, scoring='accuracy', n_jobs= -1)\n",
    "print('Cross validation treino: Média = {:.3f} Desvio Padrão = {:.3f}' .format(np.mean(scores_lr), np.std(scores_lr)))\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "#Confusion Matrix\n",
    "print('Confusion Matrix em Teste')\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "# Acurácia das previsões em relação ao resultado real\n",
    "print('Acurácia em Teste: ', accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad26da39",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277816c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train, Y_train)\n",
    "\n",
    "# Fazendo previsão\n",
    "Y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075489ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nb = cross_val_score(nb, X_train, Y_train, cv=10, scoring='accuracy', n_jobs= -1)\n",
    "print('Cross validation treino: Média = {:.3f} Desvio Padrão = {:.3f}' .format(np.mean(scores_nb), np.std(scores_nb)))\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "#Confusion Matrix\n",
    "print('Confusion Matrix em Teste')\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "# Acurácia das previsões em relação ao resultado real\n",
    "print('Acurácia em Teste: ', accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32806350",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87150cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(X_train, Y_train)\n",
    "\n",
    "# Fazendo previsão\n",
    "Y_pred = sgd.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c1a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_sgd = cross_val_score(sgd, X_train, Y_train, cv=10, scoring='accuracy', n_jobs= -1)\n",
    "print('Cross validation treino: Média = {:.3f} Desvio Padrão = {:.3f}' .format(np.mean(scores_sgd), np.std(scores_sgd)))\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "#Confusion Matrix\n",
    "print('Confusion Matrix em Teste')\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "# Acurácia das previsões em relação ao resultado real\n",
    "print('Acurácia em Teste: ', accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710a98df",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8962c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "svm.fit(X_train, Y_train)\n",
    "\n",
    "# Fazendo previsão\n",
    "Y_pred = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b428579",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_svm = cross_val_score(svm, X_train, Y_train, cv=10, scoring='accuracy', n_jobs= -1)\n",
    "print('Cross validation treino: Média = {:.3f} Desvio Padrão = {:.3f}' .format(np.mean(scores_svm), np.std(scores_svm)))\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "#Confusion Matrix\n",
    "print('Confusion Matrix em Teste')\n",
    "print(confusion_matrix(Y_test, Y_pred))\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "# Acurácia das previsões em relação ao resultado real\n",
    "print('Acurácia em Teste: ', accuracy_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4157e492",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = pd.DataFrame({'Modelo': ['Random Forest', 'Gradient Boosting', 'Logistic Regression', 'Naive Bayes', \n",
    "                            'Stochastic Gradient', 'Support Vector Machine'], \n",
    "                            'Score_Cross_Validation': [np.mean(scores_rf), np.mean(scores_gbc), np.mean(scores_lr), \n",
    "                            np.mean(scores_nb), np.mean(scores_sgd), np.mean(scores_svm)]})\n",
    "\n",
    "total_scores.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dae924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando modelo com melhor resultado no dataframe de teste\n",
    "Y_pred = df_teste.drop(['PassengerId', 'Survived'], axis=1)\n",
    "Y_pred = svm.predict(Y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c502ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'PassengerId': df_teste['PassengerId'],\n",
    "                        'Survived': Y_pred})\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "464ebb1aca84655f13a0ddeaa7b5b84aada93d077bab1a5d3df6fedaa56a8aa6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
